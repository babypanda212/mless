{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d9ee20",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/maschu09/mless/blob/main/time_series_forecasting/7_multi_model_plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2ed0a",
   "metadata": {},
   "source": [
    "# Read forecast results of all trained models, ie. \n",
    "\n",
    "1. Autoregressive SARIMAX\n",
    "2. MLP\n",
    "3. LSTM \n",
    "4. PatchTST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792cd16",
   "metadata": {},
   "source": [
    "Below is the code I used to save the forecasts of the previous models. The first code block contains the function I defined and the second code block is the usage of the function. I used both in the previous notebooks where the models were run.\n",
    "\n",
    "Google Drive URLS for loading the saved results are written.\n",
    "\n",
    "The plotting function is written after the results are read in.\n",
    "\n",
    "The plotter works for any time period and station (it just needs to be specified which time period and station we want to see). Assuming that we always use the same master dataset (all use create sequences function as well), index of first X_test will be sufficient to ID time period. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive when working in colab\n",
    "hasCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "if hasCOLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  BASEPATH = '/content/drive/MyDrive'\n",
    "else:\n",
    "  BASEPATH = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5bcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of results folder for evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save forecast results in a structured format\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def save_forecast(\n",
    "        station: str,\n",
    "        model: str,\n",
    "        context_vals,               # 1-D array-like, X test values\n",
    "        future_true,                # 1-D array-like, true future values\n",
    "        future_pred,                # 1-D array-like, predicted future values\n",
    "        episode_id,                 # int index, to identify the timeperiod\n",
    "        folder=f\"{BASEPATH}/results\"): # default folder for results\n",
    "    \"\"\"\n",
    "    One call per model-run. Stores just enough metadata to let the\n",
    "    plotting notebook know what itâ€™s looking at.\n",
    "    \"\"\"\n",
    "    import os, json, numpy as np\n",
    "    # make sure the base path exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # structure the result\n",
    "    # note: context_vals, future_true, and future_pred should be 1-D arrays\n",
    "    result = {\n",
    "        \"station\":        station,              # <- allows filtering\n",
    "        \"episode_id\":     episode_id,           # <- allows filtering\n",
    "        \"model\":          model,                # <- allows choosing of model\n",
    "        \"context\":        np.asarray(context_vals).tolist(),    # converts to numpy array and then to list\n",
    "        \"future_true\":    np.asarray(future_true).tolist(),     \n",
    "        \"future_pred\":    np.asarray(future_pred).tolist()\n",
    "    }\n",
    "\n",
    "    # create a filename based on model, station, and episode_id\n",
    "    fname = f\"{model}_{station}_{episode_id}.json\"\n",
    "\n",
    "    # save the result to a JSON file\n",
    "    with open(os.path.join(folder, fname), \"w\") as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    \n",
    "    # let user know station code and episode_id for plotting purpose\n",
    "    print(f\"Results saved as {fname}, episode_id is {episode_id} and station is {station}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for SARIMA:\n",
    "\n",
    "# episode_id = int(X_first_idx)  # Convert to native Python int\n",
    "\n",
    "\n",
    "# save_forecast(\n",
    "#     station=\"DENW094\",\n",
    "#    model=\"SARIMA\",\n",
    "#    context_vals=X_test_sample,\n",
    "#    future_true=y_test_sample,\n",
    "#    future_pred=forecast_values,\n",
    "#    episode_id=episode_id\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c3c51",
   "metadata": {},
   "source": [
    "## Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob # for file handling\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load all saved runs from the results folder\n",
    "def load_runs(run_dir, station, episode_id):\n",
    "    \"\"\"\n",
    "    Loads runs from specified directory. Needs station number and episode_id to ensure the same timeperiod and location is loaded for accurate comparison between models.\n",
    "    Returns list of results in json structure.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize list to store run data\n",
    "    runs = []\n",
    "    for path in glob.glob(f\"{run_dir}/*.json\"): # get all filepaths of result files\n",
    "        with open(path) as f:\n",
    "            r = json.load(f) # load contents of each file\n",
    "        if r[\"station\"] == station and r[\"episode_id\"] == episode_id: # check if results file matches the desired station and episode_id\n",
    "            runs.append(r)\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa33c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- choose what to visualize ---\n",
    "station = \"DENW094\"\n",
    "episode_id = 0\n",
    "# setting results folder according to my google drive\n",
    "runs = load_runs(f\"{BASEPATH}/results\", station, episode_id)\n",
    "\n",
    "# shared x-axis\n",
    "context_length = len(runs[0][\"context\"]) # length of past values of variable\n",
    "future_length = len(runs[0][\"future_true\"]) # length of forecasted value array\n",
    "context_xaxis = range(context_length) # creating time step values for x axis for the past value range\n",
    "future_xaxis = range(context_length, context_length + future_length) # creating timestep values for x axis for forecasted values range\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(context_xaxis, runs[0][\"context\"], label = \"Context\", color=\"black\") # plot past values of variable\n",
    "plt.plot(future_xaxis, runs[0][\"future_true\"], label = \"Ground truth values\", color = \"green\") # plot ground truth values of the variable\n",
    "\n",
    "# loop over all model results\n",
    "for r in runs: \n",
    "    plt.plot(future_xaxis, r[\"future_pred\"], label = r[\"model\"]) # plot predicted value from model\n",
    "\n",
    "plt.title(f\"{station} - episode {episode_id}\")\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a171f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d6c8376",
   "metadata": {},
   "source": [
    "### Check for causality\n",
    "\n",
    "ðŸ˜ˆ **Task 3:** Run a Granger test between `temp` and `o3`. Is there any directional causality?\n",
    "\n",
    "ðŸ˜ˆ **Question 3:** Why is Granger causality not the same as actual causality?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e492747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing if no2 Granger-causes o3:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpress\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting if \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Granger-causes o3:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     grangercausalitytests(\u001b[43mdataframe\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo3\u001b[39m\u001b[38;5;124m'\u001b[39m, col]], maxlag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "for col in [\"no2\", \"temp\", \"no\", \"press\"]:\n",
    "    print(f\"\\nTesting if {col} Granger-causes o3:\")\n",
    "    grangercausalitytests(dataframe[['o3', col]], maxlag=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee96cf",
   "metadata": {},
   "source": [
    "Issues:\n",
    "\n",
    "1. In Notebook 3: create sequences function : the comment says 24 hour past values and 6 hours for future, but 336 and 96 used. ie. 2 weeks and 4 days. or am I missing something?\n",
    "2. It is not clear to me if we should modify previous notebooks to save forecast results and then read them in here, because then I will have to write the code here and comment it out to show it to evaluator. \n",
    "Was I to move all model codes into one notebook? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
