{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7bde2663",
      "metadata": {
        "id": "7bde2663"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maschu09/mless/blob/main/time_series_forecasting/3_AutoRegressive_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jSe3Bjwx1Mv7",
      "metadata": {
        "id": "jSe3Bjwx1Mv7"
      },
      "source": [
        "## Load the raw data for autoregressive models\n",
        "\n",
        "In the previous notebook, we gained some insights on certain aspects of our data. In this notebook, we shall run the classical auto-regressive ARIMA model and see its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "63c24b78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "63c24b78",
        "outputId": "14d2ae0b-42fe-4b3b-ef76-0270502243fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude   latitude station_code                  datetime  temp\n",
              "0   7.567796  47.819182      DEBW073 1997-01-01 00:00:00+00:00 -10.0\n",
              "1   7.567796  47.819182      DEBW073 1997-01-01 01:00:00+00:00 -11.0\n",
              "2   7.567796  47.819182      DEBW073 1997-01-01 02:00:00+00:00 -11.0\n",
              "3   7.567796  47.819182      DEBW073 1997-01-01 03:00:00+00:00 -12.0\n",
              "4   7.567796  47.819182      DEBW073 1997-01-01 04:00:00+00:00 -12.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3db101e2-bf15-452d-a9be-8c78deb05919\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>station_code</th>\n",
              "      <th>datetime</th>\n",
              "      <th>temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.567796</td>\n",
              "      <td>47.819182</td>\n",
              "      <td>DEBW073</td>\n",
              "      <td>1997-01-01 00:00:00+00:00</td>\n",
              "      <td>-10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.567796</td>\n",
              "      <td>47.819182</td>\n",
              "      <td>DEBW073</td>\n",
              "      <td>1997-01-01 01:00:00+00:00</td>\n",
              "      <td>-11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.567796</td>\n",
              "      <td>47.819182</td>\n",
              "      <td>DEBW073</td>\n",
              "      <td>1997-01-01 02:00:00+00:00</td>\n",
              "      <td>-11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.567796</td>\n",
              "      <td>47.819182</td>\n",
              "      <td>DEBW073</td>\n",
              "      <td>1997-01-01 03:00:00+00:00</td>\n",
              "      <td>-12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.567796</td>\n",
              "      <td>47.819182</td>\n",
              "      <td>DEBW073</td>\n",
              "      <td>1997-01-01 04:00:00+00:00</td>\n",
              "      <td>-12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3db101e2-bf15-452d-a9be-8c78deb05919')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3db101e2-bf15-452d-a9be-8c78deb05919 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3db101e2-bf15-452d-a9be-8c78deb05919');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76ce124b-b4c7-4cf4-8c3c-3a6730ebc3de\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76ce124b-b4c7-4cf4-8c3c-3a6730ebc3de')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76ce124b-b4c7-4cf4-8c3c-3a6730ebc3de button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "## Raw data csv is also made available for the select stations in URL:\n",
        "url = \"https://drive.google.com/uc?export=download&id=1cmTTWY3f18SikgRBcZzhtFswIf7XwPJq\"\n",
        "dataframe = pd.read_csv(url,parse_dates=[\"datetime\"])\n",
        "dataframe = dataframe[(dataframe['datetime']>='1997-01-01') & (dataframe['datetime']<='2008-01-01')]\n",
        "variable_column = \"temp\"\n",
        "## Else if using local files:\n",
        "# import os\n",
        "# TIMESERIES_DATA_DIR = \"./content/timeseries_data/\"\n",
        "# dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"))\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "936bd018",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936bd018",
        "outputId": "5949f5b8-26c9-4b3b-956d-1addbe8bb25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(285218, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "58b300cc",
      "metadata": {
        "id": "58b300cc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0b7e3512",
      "metadata": {
        "id": "0b7e3512"
      },
      "outputs": [],
      "source": [
        "# Function to create continous time-series data with past 24 hours as input and next 6 hours as output\n",
        "def create_sequences(data, variable_column, n_past=336, n_future=96):\n",
        "    df = data.copy()\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "    df = df.sort_values(['station_code', 'datetime']).reset_index(drop=True)\n",
        "\n",
        "    # 1) Encode station_code as a small integer (categorical codes) to save memory\n",
        "    df['sc_code'] = df['station_code'].astype('category')\n",
        "\n",
        "    # 2) Boolean mask: True if exactly 1 hour after the previous row (per station)\n",
        "    is1h = (\n",
        "        df.groupby('station_code')['datetime']\n",
        "          .diff()\n",
        "          .eq(pd.Timedelta(hours=1))\n",
        "    )\n",
        "\n",
        "    # 3) Compute how many consecutive â€œTrueâ€ over (n_past + n_future - 1) rows\n",
        "    gap_window = n_past + n_future - 1\n",
        "    run = (\n",
        "        is1h.groupby(df['station_code'])\n",
        "            .rolling(window=gap_window, min_periods=gap_window)\n",
        "            .sum()\n",
        "            .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    # 4) 'ends' are indices where run == gap_window (end of a full-length continuous block)\n",
        "    ends = run[run == gap_window].index\n",
        "\n",
        "    # 5) Grab columnâ€arrays for encoded station code and the variable\n",
        "    sc_arr  = df['sc_code'].values\n",
        "    vals    = df[variable_column].values\n",
        "\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    for end_idx in ends:\n",
        "        start_idx = end_idx - gap_window\n",
        "        if start_idx >= 0 and sc_arr[start_idx] == sc_arr[end_idx]:\n",
        "            station_block = sc_arr[start_idx : end_idx + 1]\n",
        "            var_block     = vals[start_idx : end_idx + 1]\n",
        "\n",
        "            block = np.column_stack((station_block, var_block))\n",
        "\n",
        "            X_list.append(block[:n_past, :])\n",
        "            y_list.append(block[n_past:, :])\n",
        "\n",
        "    if not X_list:\n",
        "        # No valid windows\n",
        "        return np.empty((0, n_past, 2)), np.empty((0, n_future, 2))\n",
        "\n",
        "    X = np.stack(X_list)  # shape = (num_windows, n_past, 2)\n",
        "    y = np.stack(y_list)  # shape = (num_windows, n_future, 2)\n",
        "    return X, y\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef1ec10",
      "metadata": {
        "id": "7ef1ec10"
      },
      "outputs": [],
      "source": [
        "context_window = 336\n",
        "prediction_horizon = 96\n",
        "\n",
        "X, y = create_sequences(dataframe,variable_column,context_window,prediction_horizon)\n",
        "\n",
        "train_size = int(len(X) * 0.7)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive when working in colab\n",
        "hasCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
        "if hasCOLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  BASEPATH = '/content/drive/MyDrive'\n",
        "else:\n",
        "  BASEPATH = '.'"
      ],
      "metadata": {
        "id": "UKIR_AT__uMW"
      },
      "id": "UKIR_AT__uMW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e9c03ebd",
      "metadata": {
        "id": "e9c03ebd"
      },
      "source": [
        "### Forecasting with MA models: SARIMAX\n",
        "\n",
        "\n",
        "ðŸ˜ˆ **Task 1:** Try modeling without seasonal terms. How do AIC and RMSE compare?\n",
        "\n",
        "ðŸ˜ˆ **Task 2:** Add an exogenous variable like `o3` into SARIMAX and observe results.\n",
        "\n",
        "ðŸ˜ˆ **Question 1:** How does adding an exogenous variable enhance forecasting in SARIMAX?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive when working in colab\n",
        "hasCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
        "if hasCOLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  BASEPATH = '/content/drive/MyDrive'\n",
        "else:\n",
        "  BASEPATH = '.'\n",
        "\n",
        "# function to save forecast results in a structured format\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "def save_forecast(\n",
        "        station: str,\n",
        "        model: str,\n",
        "        context_vals,               # 1-D array-like, X test values\n",
        "        future_true,                # 1-D array-like, true future values\n",
        "        future_pred,                # 1-D array-like, predicted future values\n",
        "        episode_id,                 # int index, to identify the timeperiod\n",
        "        folder=f\"{BASEPATH}/results\"): # default folder for results\n",
        "    \"\"\"\n",
        "    One call per model-run. Stores just enough metadata to let the\n",
        "    plotting notebook know what itâ€™s looking at.\n",
        "    \"\"\"\n",
        "    import os, json, numpy as np\n",
        "    # make sure the base path exists\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # structure the result\n",
        "    # note: context_vals, future_true, and future_pred should be 1-D arrays\n",
        "    result = {\n",
        "        \"station\":        station,              # <- allows filtering\n",
        "        \"episode_id\":     episode_id,           # <- allows filtering\n",
        "        \"model\":          model,                # <- allows choosing of model\n",
        "        \"context\":        np.asarray(context_vals).tolist(),    # converts to numpy array and then to list\n",
        "        \"future_true\":    np.asarray(future_true).tolist(),\n",
        "        \"future_pred\":    np.asarray(future_pred).tolist()\n",
        "    }\n",
        "\n",
        "    # create a filename based on model, station, and episode_id\n",
        "    fname = f\"{model}_{station}_{episode_id}.json\"\n",
        "\n",
        "    # save the result to a JSON file\n",
        "    with open(os.path.join(folder, fname), \"w\") as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "\n",
        "    # let user know station code and episode_id for plotting purpose\n",
        "    print(f\"Results saved as {fname}, episode_id is {episode_id} and station is {station}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rUz_jVUKLW_W"
      },
      "id": "rUz_jVUKLW_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d7cf11",
      "metadata": {
        "id": "25d7cf11"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define forecast horizon (96 hours = 4 days)\n",
        "forecast_hours = 96\n",
        "\n",
        "sarima_results = {}\n",
        "\n",
        "# First sample of DENW094 station to compare with PatchTST\n",
        "X_first_idx = np.flatnonzero(X_test[:, 0, 0] == 'DENW094')[0]\n",
        "X_test_sample=X_test[X_first_idx, :, 1].astype(np.float32) # First column is station code hence adding 1\n",
        "# First sample of DENW094 station to compare with PatchTST\n",
        "y_first_idx = np.flatnonzero(X_test[:, 0, 0] == 'DENW094')[0]\n",
        "y_test_sample=y_test[y_first_idx, :, 1].astype(np.float32) # First column is station code hence adding 1\n",
        "\n",
        "# Check stationarity using ADF test\n",
        "adf_test = adfuller(X_test_sample)\n",
        "p_value = adf_test[1]\n",
        "print(f\"ADF p-value: {p_value}\")\n",
        "\n",
        "# Differencing if needed\n",
        "d = 0 if p_value < 0.05 else 1  # If p-value < 0.05, it's stationary\n",
        "seasonal_period = 24\n",
        "\n",
        "# Fit SARIMA model\n",
        "try:\n",
        "    sarima_model = SARIMAX(X_test_sample,\n",
        "        order=(1, d, 1),\n",
        "        seasonal_order=(1, d, 1, seasonal_period),\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False).fit()\n",
        "\n",
        "    fitted_values = sarima_model.fittedvalues\n",
        "    forecast = sarima_model.get_forecast(steps=forecast_hours)\n",
        "    forecast_values = forecast.predicted_mean\n",
        "    confidence_intervals = forecast.conf_int()\n",
        "\n",
        "    # Plot actual vs predicted values\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    plt.plot(range(context_window),  X_test_sample, label=\"Context\", color=\"blue\", marker=\"o\")\n",
        "    plt.plot(range(context_window, context_window + prediction_horizon), y_test_sample, label=\"Actual Future\", color=\"green\", marker=\"o\")\n",
        "    plt.plot(range(context_window, context_window + prediction_horizon), forecast_values, label=\"SARIMA Prediction\", linestyle=\"--\", color=\"orange\", marker=\"x\")\n",
        "\n",
        "    plt.title(f\"SARIMA 96-Hour Forecast vs Actual (336h) - DENW094\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"temp Levels\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    sarima_results[\"DENW094\"] = sarima_model.summary()\n",
        "\n",
        "    mse = mean_squared_error(y_test_sample, forecast_values)\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    sarima_results['DENW094'] = f\"Error: {e}\"\n",
        "\n",
        "episode_id = int(X_first_idx)   # cast to native Python int\n",
        "\n",
        "\n",
        "save_forecast(\n",
        "    station=\"DENW094\",\n",
        "    model=\"SARIMA\",\n",
        "    context_vals=X_test_sample,\n",
        "    future_true=y_test_sample,\n",
        "    future_pred=forecast_values,\n",
        "    episode_id=episode_id\n",
        ")\n",
        "\n",
        "\n",
        "sarima_results_df = pd.DataFrame.from_dict(sarima_results, orient='index', columns=['SARIMA Summary'])\n",
        "display(sarima_results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a1fc90",
      "metadata": {
        "id": "34a1fc90"
      },
      "source": [
        "## Data Preprocessing (Normalization)\n",
        "\n",
        "the snippet below uses standard Z normalization (this is a simple snippet alternatively other approaches could also be used as desired)\n",
        "\n",
        "\n",
        "ðŸ˜ˆ **Task 3:** Implement min-max normalization and compare the results visually with Z-score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lW06F1v7p8mJ",
      "metadata": {
        "id": "lW06F1v7p8mJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# German stations with good distribution temp variable observations\n",
        "station_codes = [\"DENW094\", \"DEBW073\",\"DEHE020\"]\n",
        "variable_columns = [\"temp\"]\n",
        "# station_codes = [\"DENW094\"]\n",
        "# variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a947a0",
      "metadata": {
        "id": "b8a947a0"
      },
      "outputs": [],
      "source": [
        "def standard_scaler(df, columns):\n",
        "    \"\"\"\n",
        "    Standardize the specified columns of a DataFrame by subtracting the mean\n",
        "    and dividing by the standard deviation (Z-score normalization).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        columns (list): List of column names to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with normalized columns.\n",
        "    \"\"\"\n",
        "\n",
        "    df_scaled = df.copy()\n",
        "    for col in columns:\n",
        "        df_scaled[col] = (\n",
        "            df_scaled\n",
        "            .groupby(\"station_code\")[col]\n",
        "            .transform(lambda x: (x - x.mean()) / x.std())\n",
        "        )\n",
        "    return df_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff0651c",
      "metadata": {
        "id": "7ff0651c"
      },
      "outputs": [],
      "source": [
        "dataframes = standard_scaler(dataframe, variable_columns)\n",
        "dataframes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab0b83f",
      "metadata": {
        "id": "3ab0b83f"
      },
      "outputs": [],
      "source": [
        "TIMESERIES_DATA_DIR = \"./content/timeseries_data/\"\n",
        "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"), index=False)\n",
        "dataframes.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346d227f",
      "metadata": {
        "id": "346d227f"
      },
      "source": [
        "### Load the normalized data preparing samples for ML models.\n",
        "\n",
        "\n",
        "> Samples are needed for sequence models and transformer models for input\n",
        "\n",
        "ðŸ˜ˆ **Task 4:** What are some key differences between AR models and sequence models like RNNs or Transformers?\n",
        "\n",
        "ðŸ˜ˆ **Question 2:** Why is it important to maintain time continuity when preparing samples for sequence models?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sRXE9Nxmz3Cu",
      "metadata": {
        "id": "sRXE9Nxmz3Cu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "## Normalized data csv is also made available for the select stations in URL:\n",
        "url = \"https://drive.google.com/uc?export=download&id=1Eui59GyTXNv839WijdZ0CkzuMubmZQz1\"\n",
        "dataframe = pd.read_csv(url,parse_dates=[\"datetime\"])\n",
        "dataframe = dataframe[(dataframe['datetime']>='1997-01-01') & (dataframe['datetime']<='2008-01-01')]\n",
        "## Else if using local files:\n",
        "# dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"))\n",
        "variable_column = \"temp\"\n",
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76b26097",
      "metadata": {
        "id": "76b26097"
      },
      "source": [
        "80/20 train/test split chosen for illustration\n",
        "\n",
        "ðŸ˜ˆ **Task 5:** Try a rolling-window cross-validation strategy. How does model performance vary?\n",
        "\n",
        "ðŸ˜ˆ **Question 3:** What are the pitfalls of using random splits in timeseries forecasting?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181d6c87",
      "metadata": {
        "id": "181d6c87"
      },
      "outputs": [],
      "source": [
        "context_window = 336\n",
        "prediction_horizon = 96\n",
        "\n",
        "X, y = create_sequences(dataframe,variable_column,context_window,prediction_horizon)\n",
        "\n",
        "train_size = int(len(X) * 0.7)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059a8dfe",
      "metadata": {
        "id": "059a8dfe"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"./content/X_train.pkl\", \"wb\") as f:\n",
        "    pickle.dump(X_train, f)\n",
        "\n",
        "with open(\"./content/X_test.pkl\", \"wb\") as f:\n",
        "    pickle.dump(X_test, f)\n",
        "\n",
        "with open(\"./content/y_train.pkl\", \"wb\") as f:\n",
        "    pickle.dump(y_train, f)\n",
        "\n",
        "with open(\"./content/y_test.pkl\", \"wb\") as f:\n",
        "    pickle.dump(y_test, f)\n",
        "\n",
        "print(\"Train/test datasets saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2361f6d",
      "metadata": {
        "id": "d2361f6d"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "## Processed data .pkl files are also made available for the select stations in URL\n",
        "# Please download the files and place them in content subfolder\n",
        "# else modify below path according to your chosen local download path:\n",
        "# univariate case (temp) : https://drive.google.com/drive/folders/197WGFswCLYinkx-48XBMQKILwJQMokd0?usp=sharing\n",
        "\n",
        "with open(\"./content/X_train.pkl\", \"rb\") as f:\n",
        "    X_train = pickle.load(f)\n",
        "\n",
        "with open(\"./content/X_test.pkl\", \"rb\") as f:\n",
        "    X_test = pickle.load(f)\n",
        "\n",
        "with open(\"./content/y_train.pkl\", \"rb\") as f:\n",
        "    y_train = pickle.load(f)\n",
        "\n",
        "with open(\"./content/y_test.pkl\", \"rb\") as f:\n",
        "    y_test = pickle.load(f)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9924af7",
      "metadata": {
        "id": "a9924af7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "346d227f"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}