{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maschu09/mless/blob/main/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LyuLtJcZR1_"
      },
      "source": [
        "# Skip connection in  [Resnet](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "In ResNet architectures, a skip connection, often referred to as a \"skip layer,\" provides a shortcut path for the input tensor to bypass one or more layers in the network.  Instead of directly feeding the output of a layer to the next, the skip connection adds the input tensor to the output of the layer.  Mathematically, this looks like:\n",
        "\n",
        "`Output = F(Input) + Input`\n",
        "\n",
        "where `F` represents the transformations performed by one or more layers within the residual block, and `Input` is the activation from the previous layer.\n",
        "\n",
        "### Benefits of skip connection:\n",
        "\n",
        "* **Addressing Vanishing/Exploding Gradients:**  The skip connection facilitates the flow of gradients during backpropagation, helping to mitigate the vanishing or exploding gradient problem. The direct path for the gradients allows them to propagate more easily through the network, especially in deep architectures where these problems are more pronounced.  The gradients have an easier path to update weights in earlier layers, allowing the network to learn effectively.\n",
        "\n",
        "* **Enabling Deeper Networks:**  By easing gradient flow, skip connections enable the training of significantly deeper networks.  Deeper networks, in theory, have greater capacity to learn complex features. Without skip connections, very deep networks are difficult or impossible to train due to vanishing gradients.\n",
        "\n",
        "* **Improved Optimization:** Skip connections are not simply a shortcut for the data, but a mechanism to optimize the network. The network learns *residual functions* — the difference between the desired output and the input — rather than learning the complete mapping directly.  This allows the network to learn incremental improvements on top of what's already been learned.\n",
        "\n",
        "\n",
        "NB: The skip connection is a crucial component of ResNet architectures, allowing for the construction and training of extremely deep networks by improving gradient flow and enabling the learning of residual mappings. This has revolutionized the field of Computer Vision which has become the state of the art model and showed competitive results on [Imagenet](https://www.image-net.org/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "IfR9hRQoZCP1",
        "outputId": "b1e96211-638e-4dcf-cdbd-51b81ca652ba"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9fe02c5d44e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##import modules whichever required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSkipLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "## Write a torch module for one skip layer as shown in the figure below\n",
        "\n",
        "## A layer in the figure represent a sequential layer of conv layer -> batchnorm -> Activation function(ReLu)\n",
        "\n",
        "## We expect by now, you have learnt about different arguments of torch.nn.Conv2D module like in_channels, out_channels, kernel_size, stride, and padding\n",
        "\n",
        "##import modules whichever required\n",
        "\n",
        "class SkipLayer(torch.nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    #write your code here\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "rAan-hkLeU7E",
        "outputId": "8ea6b11f-57c4-468d-ba95-2853b4349e0f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-02f19f118b3e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 28 \\times 28 - height \\times width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrandom_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mskip_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSkipLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "## Test your module\n",
        "\n",
        "# 16-batchsize\n",
        "# 4-channels\n",
        "# 28 \\times 28 - height \\times width\n",
        "\n",
        "random_sample = torch.randn((16,4,28,28))\n",
        "skip_layer = SkipLayer()\n",
        "print(skip_layer(random_sample).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6iPzuLrn7JP"
      },
      "source": [
        "## Torchvision's Resnet [github](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py)\n",
        "Now, that you have learnt what is skip connection module, now its time to use a Resnet module to our classification tasks on SAT-6 dataset.\n",
        "\n",
        "Try to replace our predefined CNN with Resnet. Use already available Resnet module\n",
        "\n",
        "Hints: The Resnet module from torchvision is developed for RGB images where input image has 3 channels. Please try to change it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_qrGkQIEw2z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM9JHoN3DAD+l+Jfti4jchl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
